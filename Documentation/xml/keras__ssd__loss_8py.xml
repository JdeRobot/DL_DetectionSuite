<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.13">
  <compounddef id="keras__ssd__loss_8py" kind="file" language="Python">
    <compoundname>keras_ssd_loss.py</compoundname>
    <innerclass refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss" prot="public">keras_utils::keras_ssd_loss::SSDLoss</innerclass>
    <innernamespace refid="namespacekeras__utils_1_1keras__ssd__loss">keras_utils::keras_ssd_loss</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1" refid="namespacekeras__utils_1_1keras__ssd__loss" refkind="compound"><highlight class="stringliteral">&apos;&apos;&apos;</highlight></codeline>
<codeline lineno="2"><highlight class="stringliteral">The<sp/>Keras-compatible<sp/>loss<sp/>function<sp/>for<sp/>the<sp/>SSD<sp/>model.<sp/>Currently<sp/>supports<sp/>TensorFlow<sp/>only.</highlight></codeline>
<codeline lineno="3"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="4"><highlight class="stringliteral">Copyright<sp/>(C)<sp/>2017<sp/>Pierluigi<sp/>Ferrari</highlight></codeline>
<codeline lineno="5"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="6"><highlight class="stringliteral">This<sp/>program<sp/>is<sp/>free<sp/>software:<sp/>you<sp/>can<sp/>redistribute<sp/>it<sp/>and/or<sp/>modify</highlight></codeline>
<codeline lineno="7"><highlight class="stringliteral">it<sp/>under<sp/>the<sp/>terms<sp/>of<sp/>the<sp/>GNU<sp/>General<sp/>Public<sp/>License<sp/>as<sp/>published<sp/>by</highlight></codeline>
<codeline lineno="8"><highlight class="stringliteral">the<sp/>Free<sp/>Software<sp/>Foundation,<sp/>either<sp/>version<sp/>3<sp/>of<sp/>the<sp/>License,<sp/>or</highlight></codeline>
<codeline lineno="9"><highlight class="stringliteral">(at<sp/>your<sp/>option)<sp/>any<sp/>later<sp/>version.</highlight></codeline>
<codeline lineno="10"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="11"><highlight class="stringliteral">This<sp/>program<sp/>is<sp/>distributed<sp/>in<sp/>the<sp/>hope<sp/>that<sp/>it<sp/>will<sp/>be<sp/>useful,</highlight></codeline>
<codeline lineno="12"><highlight class="stringliteral">but<sp/>WITHOUT<sp/>ANY<sp/>WARRANTY;<sp/>without<sp/>even<sp/>the<sp/>implied<sp/>warranty<sp/>of</highlight></codeline>
<codeline lineno="13"><highlight class="stringliteral">MERCHANTABILITY<sp/>or<sp/>FITNESS<sp/>FOR<sp/>A<sp/>PARTICULAR<sp/>PURPOSE.<sp/><sp/>See<sp/>the</highlight></codeline>
<codeline lineno="14"><highlight class="stringliteral">GNU<sp/>General<sp/>Public<sp/>License<sp/>for<sp/>more<sp/>details.</highlight></codeline>
<codeline lineno="15"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="16"><highlight class="stringliteral">You<sp/>should<sp/>have<sp/>received<sp/>a<sp/>copy<sp/>of<sp/>the<sp/>GNU<sp/>General<sp/>Public<sp/>License</highlight></codeline>
<codeline lineno="17"><highlight class="stringliteral">along<sp/>with<sp/>this<sp/>program.<sp/><sp/>If<sp/>not,<sp/>see<sp/>&lt;http://www.gnu.org/licenses/&gt;.</highlight></codeline>
<codeline lineno="18"><highlight class="stringliteral">&apos;&apos;&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight></codeline>
<codeline lineno="20"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>__future__<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>division</highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>tensorflow<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>tf</highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight></codeline>
<codeline lineno="23" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss" kindref="compound">SSDLoss</ref>:</highlight></codeline>
<codeline lineno="24"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;&apos;&apos;</highlight></codeline>
<codeline lineno="25"><highlight class="stringliteral"><sp/><sp/><sp/><sp/>The<sp/>SSD<sp/>loss,<sp/>see<sp/>https://arxiv.org/abs/1512.02325.</highlight></codeline>
<codeline lineno="26"><highlight class="stringliteral"><sp/><sp/><sp/><sp/>&apos;&apos;&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="27"><highlight class="normal"></highlight></codeline>
<codeline lineno="28"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a2689ede880461cb86574c15d98d200f2" kindref="member">__init__</ref>(self,</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>neg_pos_ratio=3,</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_neg_min=0,</highlight></codeline>
<codeline lineno="31" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a2689ede880461cb86574c15d98d200f2" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>alpha=1.0):</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;&apos;&apos;</highlight></codeline>
<codeline lineno="33"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Arguments:</highlight></codeline>
<codeline lineno="34"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>neg_pos_ratio<sp/>(int,<sp/>optional):<sp/>The<sp/>maximum<sp/>ratio<sp/>of<sp/>negative<sp/>(i.e.<sp/>background)</highlight></codeline>
<codeline lineno="35"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>to<sp/>positive<sp/>ground<sp/>truth<sp/>boxes<sp/>to<sp/>include<sp/>in<sp/>the<sp/>loss<sp/>computation.</highlight></codeline>
<codeline lineno="36"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>There<sp/>are<sp/>no<sp/>actual<sp/>background<sp/>ground<sp/>truth<sp/>boxes<sp/>of<sp/>course,<sp/>but<sp/>`y_true`</highlight></codeline>
<codeline lineno="37"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>contains<sp/>anchor<sp/>boxes<sp/>labeled<sp/>with<sp/>the<sp/>background<sp/>class.<sp/>Since</highlight></codeline>
<codeline lineno="38"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>the<sp/>number<sp/>of<sp/>background<sp/>boxes<sp/>in<sp/>`y_true`<sp/>will<sp/>usually<sp/>exceed</highlight></codeline>
<codeline lineno="39"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>the<sp/>number<sp/>of<sp/>positive<sp/>boxes<sp/>by<sp/>far,<sp/>it<sp/>is<sp/>necessary<sp/>to<sp/>balance</highlight></codeline>
<codeline lineno="40"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>their<sp/>influence<sp/>on<sp/>the<sp/>loss.<sp/>Defaults<sp/>to<sp/>3<sp/>following<sp/>the<sp/>paper.</highlight></codeline>
<codeline lineno="41"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_neg_min<sp/>(int,<sp/>optional):<sp/>The<sp/>minimum<sp/>number<sp/>of<sp/>negative<sp/>ground<sp/>truth<sp/>boxes<sp/>to</highlight></codeline>
<codeline lineno="42"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>enter<sp/>the<sp/>loss<sp/>computation<sp/>*per<sp/>batch*.<sp/>This<sp/>argument<sp/>can<sp/>be<sp/>used<sp/>to<sp/>make</highlight></codeline>
<codeline lineno="43"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sure<sp/>that<sp/>the<sp/>model<sp/>learns<sp/>from<sp/>a<sp/>minimum<sp/>number<sp/>of<sp/>negatives<sp/>in<sp/>batches</highlight></codeline>
<codeline lineno="44"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>in<sp/>which<sp/>there<sp/>are<sp/>very<sp/>few,<sp/>or<sp/>even<sp/>none<sp/>at<sp/>all,<sp/>positive<sp/>ground<sp/>truth</highlight></codeline>
<codeline lineno="45"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>boxes.<sp/>It<sp/>defaults<sp/>to<sp/>0<sp/>and<sp/>if<sp/>used,<sp/>it<sp/>should<sp/>be<sp/>set<sp/>to<sp/>a<sp/>value<sp/>that</highlight></codeline>
<codeline lineno="46"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>stands<sp/>in<sp/>reasonable<sp/>proportion<sp/>to<sp/>the<sp/>batch<sp/>size<sp/>used<sp/>for<sp/>training.</highlight></codeline>
<codeline lineno="47"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>alpha<sp/>(float,<sp/>optional):<sp/>A<sp/>factor<sp/>to<sp/>weight<sp/>the<sp/>localization<sp/>loss<sp/>in<sp/>the</highlight></codeline>
<codeline lineno="48"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>computation<sp/>of<sp/>the<sp/>total<sp/>loss.<sp/>Defaults<sp/>to<sp/>1.0<sp/>following<sp/>the<sp/>paper.</highlight></codeline>
<codeline lineno="49"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&apos;&apos;&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="50" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af9f522438bf7085bea81c6431baf427b" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af9f522438bf7085bea81c6431baf427b" kindref="member">neg_pos_ratio</ref><sp/>=<sp/>neg_pos_ratio</highlight></codeline>
<codeline lineno="51" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a933f7528c9efabe7dd5c91fd18d9cbf9" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a933f7528c9efabe7dd5c91fd18d9cbf9" kindref="member">n_neg_min</ref><sp/>=<sp/>n_neg_min</highlight></codeline>
<codeline lineno="52" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1afb5702fa295ff501d5b4baf09e2af409" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1afb5702fa295ff501d5b4baf09e2af409" kindref="member">alpha</ref><sp/>=<sp/>alpha</highlight></codeline>
<codeline lineno="53"><highlight class="normal"></highlight></codeline>
<codeline lineno="54" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af8b9efac79d769cb5d55728946798bd3" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af8b9efac79d769cb5d55728946798bd3" kindref="member">smooth_L1_loss</ref>(self,<sp/>y_true,<sp/>y_pred):</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;&apos;&apos;</highlight></codeline>
<codeline lineno="56"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Compute<sp/>smooth<sp/>L1<sp/>loss,<sp/>see<sp/>references.</highlight></codeline>
<codeline lineno="57"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="58"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Arguments:</highlight></codeline>
<codeline lineno="59"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_true<sp/>(nD<sp/>tensor):<sp/>A<sp/>TensorFlow<sp/>tensor<sp/>of<sp/>any<sp/>shape<sp/>containing<sp/>the<sp/>ground<sp/>truth<sp/>data.</highlight></codeline>
<codeline lineno="60"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>In<sp/>this<sp/>context,<sp/>the<sp/>expected<sp/>tensor<sp/>has<sp/>shape<sp/>`(batch_size,<sp/>#boxes,<sp/>4)`<sp/>and</highlight></codeline>
<codeline lineno="61"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>contains<sp/>the<sp/>ground<sp/>truth<sp/>bounding<sp/>box<sp/>coordinates,<sp/>where<sp/>the<sp/>last<sp/>dimension</highlight></codeline>
<codeline lineno="62"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>contains<sp/>`(xmin,<sp/>xmax,<sp/>ymin,<sp/>ymax)`.</highlight></codeline>
<codeline lineno="63"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_pred<sp/>(nD<sp/>tensor):<sp/>A<sp/>TensorFlow<sp/>tensor<sp/>of<sp/>identical<sp/>structure<sp/>to<sp/>`y_true`<sp/>containing</highlight></codeline>
<codeline lineno="64"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>the<sp/>predicted<sp/>data,<sp/>in<sp/>this<sp/>context<sp/>the<sp/>predicted<sp/>bounding<sp/>box<sp/>coordinates.</highlight></codeline>
<codeline lineno="65"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="66"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="67"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>smooth<sp/>L1<sp/>loss,<sp/>a<sp/>nD-1<sp/>Tensorflow<sp/>tensor.<sp/>In<sp/>this<sp/>context<sp/>a<sp/>2D<sp/>tensor</highlight></codeline>
<codeline lineno="68"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>of<sp/>shape<sp/>(batch,<sp/>n_boxes_total).</highlight></codeline>
<codeline lineno="69"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="70"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>References:</highlight></codeline>
<codeline lineno="71"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>https://arxiv.org/abs/1504.08083</highlight></codeline>
<codeline lineno="72"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&apos;&apos;&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>absolute_loss<sp/>=<sp/>tf.abs(y_true<sp/>-<sp/>y_pred)</highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>square_loss<sp/>=<sp/>0.5<sp/>*<sp/>(y_true<sp/>-<sp/>y_pred)**2</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>l1_loss<sp/>=<sp/>tf.where(tf.less(absolute_loss,<sp/>1.0),<sp/>square_loss,<sp/>absolute_loss<sp/>-<sp/>0.5)</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>tf.reduce_sum(l1_loss,<sp/>axis=-1)</highlight></codeline>
<codeline lineno="77"><highlight class="normal"></highlight></codeline>
<codeline lineno="78" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1ac961f7061c048c565a859f8d42159a0d" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1ac961f7061c048c565a859f8d42159a0d" kindref="member">log_loss</ref>(self,<sp/>y_true,<sp/>y_pred):</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;&apos;&apos;</highlight></codeline>
<codeline lineno="80"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Compute<sp/>the<sp/>softmax<sp/>log<sp/>loss.</highlight></codeline>
<codeline lineno="81"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="82"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Arguments:</highlight></codeline>
<codeline lineno="83"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_true<sp/>(nD<sp/>tensor):<sp/>A<sp/>TensorFlow<sp/>tensor<sp/>of<sp/>any<sp/>shape<sp/>containing<sp/>the<sp/>ground<sp/>truth<sp/>data.</highlight></codeline>
<codeline lineno="84"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>In<sp/>this<sp/>context,<sp/>the<sp/>expected<sp/>tensor<sp/>has<sp/>shape<sp/>(batch_size,<sp/>#boxes,<sp/>#classes)</highlight></codeline>
<codeline lineno="85"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>and<sp/>contains<sp/>the<sp/>ground<sp/>truth<sp/>bounding<sp/>box<sp/>categories.</highlight></codeline>
<codeline lineno="86"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_pred<sp/>(nD<sp/>tensor):<sp/>A<sp/>TensorFlow<sp/>tensor<sp/>of<sp/>identical<sp/>structure<sp/>to<sp/>`y_true`<sp/>containing</highlight></codeline>
<codeline lineno="87"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>the<sp/>predicted<sp/>data,<sp/>in<sp/>this<sp/>context<sp/>the<sp/>predicted<sp/>bounding<sp/>box<sp/>categories.</highlight></codeline>
<codeline lineno="88"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="89"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="90"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>softmax<sp/>log<sp/>loss,<sp/>a<sp/>nD-1<sp/>Tensorflow<sp/>tensor.<sp/>In<sp/>this<sp/>context<sp/>a<sp/>2D<sp/>tensor</highlight></codeline>
<codeline lineno="91"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>of<sp/>shape<sp/>(batch,<sp/>n_boxes_total).</highlight></codeline>
<codeline lineno="92"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&apos;&apos;&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Make<sp/>sure<sp/>that<sp/>`y_pred`<sp/>doesn&apos;t<sp/>contain<sp/>any<sp/>zeros<sp/>(which<sp/>would<sp/>break<sp/>the<sp/>log<sp/>function)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_pred<sp/>=<sp/>tf.maximum(y_pred,<sp/>1e-15)</highlight></codeline>
<codeline lineno="95"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Compute<sp/>the<sp/>log<sp/>loss</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>log_loss<sp/>=<sp/>-tf.reduce_sum(y_true<sp/>*<sp/>tf.log(y_pred),<sp/>axis=-1)</highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>log_loss</highlight></codeline>
<codeline lineno="98"><highlight class="normal"></highlight></codeline>
<codeline lineno="99" refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a4f40f84c97462853d5b19373e7c5933b" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a4f40f84c97462853d5b19373e7c5933b" kindref="member">compute_loss</ref>(self,<sp/>y_true,<sp/>y_pred):</highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;&apos;&apos;</highlight></codeline>
<codeline lineno="101"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Compute<sp/>the<sp/>loss<sp/>of<sp/>the<sp/>SSD<sp/>model<sp/>prediction<sp/>against<sp/>the<sp/>ground<sp/>truth.</highlight></codeline>
<codeline lineno="102"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="103"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Arguments:</highlight></codeline>
<codeline lineno="104"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_true<sp/>(array):<sp/>A<sp/>Numpy<sp/>array<sp/>of<sp/>shape<sp/>`(batch_size,<sp/>#boxes,<sp/>#classes<sp/>+<sp/>12)`,</highlight></codeline>
<codeline lineno="105"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>where<sp/>`#boxes`<sp/>is<sp/>the<sp/>total<sp/>number<sp/>of<sp/>boxes<sp/>that<sp/>the<sp/>model<sp/>predicts</highlight></codeline>
<codeline lineno="106"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>per<sp/>image.<sp/>Be<sp/>careful<sp/>to<sp/>make<sp/>sure<sp/>that<sp/>the<sp/>index<sp/>of<sp/>each<sp/>given</highlight></codeline>
<codeline lineno="107"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>box<sp/>in<sp/>`y_true`<sp/>is<sp/>the<sp/>same<sp/>as<sp/>the<sp/>index<sp/>for<sp/>the<sp/>corresponding</highlight></codeline>
<codeline lineno="108"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>box<sp/>in<sp/>`y_pred`.<sp/>The<sp/>last<sp/>axis<sp/>must<sp/>have<sp/>length<sp/>`#classes<sp/>+<sp/>12`<sp/>and<sp/>contain</highlight></codeline>
<codeline lineno="109"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>`[classes<sp/>one-hot<sp/>encoded,<sp/>4<sp/>ground<sp/>truth<sp/>box<sp/>coordinate<sp/>offsets,<sp/>8<sp/>arbitrary<sp/>entries]`</highlight></codeline>
<codeline lineno="110"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>in<sp/>this<sp/>order,<sp/>including<sp/>the<sp/>background<sp/>class.<sp/>The<sp/>last<sp/>eight<sp/>entries<sp/>of<sp/>the</highlight></codeline>
<codeline lineno="111"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>last<sp/>axis<sp/>are<sp/>not<sp/>used<sp/>by<sp/>this<sp/>function<sp/>and<sp/>therefore<sp/>their<sp/>contents<sp/>are</highlight></codeline>
<codeline lineno="112"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>irrelevant,<sp/>they<sp/>only<sp/>exist<sp/>so<sp/>that<sp/>`y_true`<sp/>has<sp/>the<sp/>same<sp/>shape<sp/>as<sp/>`y_pred`,</highlight></codeline>
<codeline lineno="113"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>where<sp/>the<sp/>last<sp/>four<sp/>entries<sp/>of<sp/>the<sp/>last<sp/>axis<sp/>contain<sp/>the<sp/>anchor<sp/>box</highlight></codeline>
<codeline lineno="114"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>coordinates,<sp/>which<sp/>are<sp/>needed<sp/>during<sp/>inference.<sp/>Important:<sp/>Boxes<sp/>that</highlight></codeline>
<codeline lineno="115"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>you<sp/>want<sp/>the<sp/>cost<sp/>function<sp/>to<sp/>ignore<sp/>need<sp/>to<sp/>have<sp/>a<sp/>one-hot</highlight></codeline>
<codeline lineno="116"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>class<sp/>vector<sp/>of<sp/>all<sp/>zeros.</highlight></codeline>
<codeline lineno="117"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>y_pred<sp/>(Keras<sp/>tensor):<sp/>The<sp/>model<sp/>prediction.<sp/>The<sp/>shape<sp/>is<sp/>identical</highlight></codeline>
<codeline lineno="118"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>to<sp/>that<sp/>of<sp/>`y_true`,<sp/>i.e.<sp/>`(batch_size,<sp/>#boxes,<sp/>#classes<sp/>+<sp/>12)`.</highlight></codeline>
<codeline lineno="119"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>last<sp/>axis<sp/>must<sp/>contain<sp/>entries<sp/>in<sp/>the<sp/>format</highlight></codeline>
<codeline lineno="120"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>`[classes<sp/>one-hot<sp/>encoded,<sp/>4<sp/>predicted<sp/>box<sp/>coordinate<sp/>offsets,<sp/>8<sp/>arbitrary<sp/>entries]`.</highlight></codeline>
<codeline lineno="121"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="122"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="123"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>A<sp/>scalar,<sp/>the<sp/>total<sp/>multitask<sp/>loss<sp/>for<sp/>classification<sp/>and<sp/>localization.</highlight></codeline>
<codeline lineno="124"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&apos;&apos;&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="125"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af9f522438bf7085bea81c6431baf427b" kindref="member">neg_pos_ratio</ref><sp/>=<sp/>tf.constant(self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af9f522438bf7085bea81c6431baf427b" kindref="member">neg_pos_ratio</ref>)</highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a933f7528c9efabe7dd5c91fd18d9cbf9" kindref="member">n_neg_min</ref><sp/>=<sp/>tf.constant(self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a933f7528c9efabe7dd5c91fd18d9cbf9" kindref="member">n_neg_min</ref>)</highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1afb5702fa295ff501d5b4baf09e2af409" kindref="member">alpha</ref><sp/>=<sp/>tf.constant(self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1afb5702fa295ff501d5b4baf09e2af409" kindref="member">alpha</ref>)</highlight></codeline>
<codeline lineno="128"><highlight class="normal"></highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>batch_size<sp/>=<sp/>tf.shape(y_pred)[0]<sp/></highlight><highlight class="comment">#<sp/>Output<sp/>dtype:<sp/>tf.int32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_boxes<sp/>=<sp/>tf.shape(y_pred)[1]<sp/></highlight><highlight class="comment">#<sp/>Output<sp/>dtype:<sp/>tf.int32,<sp/>note<sp/>that<sp/>`n_boxes`<sp/>in<sp/>this<sp/>context<sp/>denotes<sp/>the<sp/>total<sp/>number<sp/>of<sp/>boxes<sp/>per<sp/>image,<sp/>not<sp/>the<sp/>number<sp/>of<sp/>boxes<sp/>per<sp/>cell.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="131"><highlight class="normal"></highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>1:<sp/>Compute<sp/>the<sp/>losses<sp/>for<sp/>class<sp/>and<sp/>box<sp/>predictions<sp/>for<sp/>every<sp/>box.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="133"><highlight class="normal"></highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>classification_loss<sp/>=<sp/>tf.to_float(self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1ac961f7061c048c565a859f8d42159a0d" kindref="member">log_loss</ref>(y_true[:,:,:-12],<sp/>y_pred[:,:,:-12]))<sp/></highlight><highlight class="comment">#<sp/>Output<sp/>shape:<sp/>(batch_size,<sp/>n_boxes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>localization_loss<sp/>=<sp/>tf.to_float(self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af8b9efac79d769cb5d55728946798bd3" kindref="member">smooth_L1_loss</ref>(y_true[:,:,-12:-8],<sp/>y_pred[:,:,-12:-8]))<sp/></highlight><highlight class="comment">#<sp/>Output<sp/>shape:<sp/>(batch_size,<sp/>n_boxes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="136"><highlight class="normal"></highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>2:<sp/>Compute<sp/>the<sp/>classification<sp/>losses<sp/>for<sp/>the<sp/>positive<sp/>and<sp/>negative<sp/>targets.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="138"><highlight class="normal"></highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Create<sp/>masks<sp/>for<sp/>the<sp/>positive<sp/>and<sp/>negative<sp/>ground<sp/>truth<sp/>classes.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>negatives<sp/>=<sp/>y_true[:,:,0]<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,<sp/>n_boxes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>positives<sp/>=<sp/>tf.to_float(tf.reduce_max(y_true[:,:,1:-12],<sp/>axis=-1))<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,<sp/>n_boxes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="142"><highlight class="normal"></highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Count<sp/>the<sp/>number<sp/>of<sp/>positive<sp/>boxes<sp/>(classes<sp/>1<sp/>to<sp/>n)<sp/>in<sp/>y_true<sp/>across<sp/>the<sp/>whole<sp/>batch.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_positive<sp/>=<sp/>tf.reduce_sum(positives)</highlight></codeline>
<codeline lineno="145"><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Now<sp/>mask<sp/>all<sp/>negative<sp/>boxes<sp/>and<sp/>sum<sp/>up<sp/>the<sp/>losses<sp/>for<sp/>the<sp/>positive<sp/>boxes<sp/>PER<sp/>batch<sp/>item</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>(Keras<sp/>loss<sp/>functions<sp/>must<sp/>output<sp/>one<sp/>scalar<sp/>loss<sp/>value<sp/>PER<sp/>batch<sp/>item,<sp/>rather<sp/>than<sp/>just</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>one<sp/>scalar<sp/>for<sp/>the<sp/>entire<sp/>batch,<sp/>that&apos;s<sp/>why<sp/>we&apos;re<sp/>not<sp/>summing<sp/>across<sp/>all<sp/>axes).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>pos_class_loss<sp/>=<sp/>tf.reduce_sum(classification_loss<sp/>*<sp/>positives,<sp/>axis=-1)<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"></highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Compute<sp/>the<sp/>classification<sp/>loss<sp/>for<sp/>the<sp/>negative<sp/>default<sp/>boxes<sp/>(if<sp/>there<sp/>are<sp/>any).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="152"><highlight class="normal"></highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>First,<sp/>compute<sp/>the<sp/>classification<sp/>loss<sp/>for<sp/>all<sp/>negative<sp/>boxes.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>neg_class_loss_all<sp/>=<sp/>classification_loss<sp/>*<sp/>negatives<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,<sp/>n_boxes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_neg_losses<sp/>=<sp/>tf.count_nonzero(neg_class_loss_all,<sp/>dtype=tf.int32)<sp/></highlight><highlight class="comment">#<sp/>The<sp/>number<sp/>of<sp/>non-zero<sp/>loss<sp/>entries<sp/>in<sp/>`neg_class_loss_all`</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>What&apos;s<sp/>the<sp/>point<sp/>of<sp/>`n_neg_losses`?<sp/>For<sp/>the<sp/>next<sp/>step,<sp/>which<sp/>will<sp/>be<sp/>to<sp/>compute<sp/>which<sp/>negative<sp/>boxes<sp/>enter<sp/>the<sp/>classification</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>loss,<sp/>we<sp/>don&apos;t<sp/>just<sp/>want<sp/>to<sp/>know<sp/>how<sp/>many<sp/>negative<sp/>ground<sp/>truth<sp/>boxes<sp/>there<sp/>are,<sp/>but<sp/>for<sp/>how<sp/>many<sp/>of<sp/>those<sp/>there<sp/>actually<sp/>is</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>a<sp/>positive<sp/>(i.e.<sp/>non-zero)<sp/>loss.<sp/>This<sp/>is<sp/>necessary<sp/>because<sp/>`tf.nn.top-k()`<sp/>in<sp/>the<sp/>function<sp/>below<sp/>will<sp/>pick<sp/>the<sp/>top<sp/>k<sp/>boxes<sp/>with</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>the<sp/>highest<sp/>losses<sp/>no<sp/>matter<sp/>what,<sp/>even<sp/>if<sp/>it<sp/>receives<sp/>a<sp/>vector<sp/>where<sp/>all<sp/>losses<sp/>are<sp/>zero.<sp/>In<sp/>the<sp/>unlikely<sp/>event<sp/>that<sp/>all<sp/>negative</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>classification<sp/>losses<sp/>ARE<sp/>actually<sp/>zero<sp/>though,<sp/>this<sp/>behavior<sp/>might<sp/>lead<sp/>to<sp/>`tf.nn.top-k()`<sp/>returning<sp/>the<sp/>indices<sp/>of<sp/>positive</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>boxes,<sp/>leading<sp/>to<sp/>an<sp/>incorrect<sp/>negative<sp/>classification<sp/>loss<sp/>computation,<sp/>and<sp/>hence<sp/>an<sp/>incorrect<sp/>overall<sp/>loss<sp/>computation.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="162"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>We<sp/>therefore<sp/>need<sp/>to<sp/>make<sp/>sure<sp/>that<sp/>`n_negative_keep`,<sp/>which<sp/>assumes<sp/>the<sp/>role<sp/>of<sp/>the<sp/>`k`<sp/>argument<sp/>in<sp/>`tf.nn.top-k()`,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>is<sp/>at<sp/>most<sp/>the<sp/>number<sp/>of<sp/>negative<sp/>boxes<sp/>for<sp/>which<sp/>there<sp/>is<sp/>a<sp/>positive<sp/>classification<sp/>loss.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="164"><highlight class="normal"></highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Compute<sp/>the<sp/>number<sp/>of<sp/>negative<sp/>examples<sp/>we<sp/>want<sp/>to<sp/>account<sp/>for<sp/>in<sp/>the<sp/>loss.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>We&apos;ll<sp/>keep<sp/>at<sp/>most<sp/>`self.neg_pos_ratio`<sp/>times<sp/>the<sp/>number<sp/>of<sp/>positives<sp/>in<sp/>`y_true`,<sp/>but<sp/>at<sp/>least<sp/>`self.n_neg_min`<sp/>(unless<sp/>`n_neg_loses`<sp/>is<sp/>smaller).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_negative_keep<sp/>=<sp/>tf.minimum(tf.maximum(self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1af9f522438bf7085bea81c6431baf427b" kindref="member">neg_pos_ratio</ref><sp/>*<sp/>tf.to_int32(n_positive),<sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1a933f7528c9efabe7dd5c91fd18d9cbf9" kindref="member">n_neg_min</ref>),<sp/>n_neg_losses)</highlight></codeline>
<codeline lineno="168"><highlight class="normal"></highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>In<sp/>the<sp/>unlikely<sp/>case<sp/>when<sp/>either<sp/>(1)<sp/>there<sp/>are<sp/>no<sp/>negative<sp/>ground<sp/>truth<sp/>boxes<sp/>at<sp/>all</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>or<sp/>(2)<sp/>the<sp/>classification<sp/>loss<sp/>for<sp/>all<sp/>negative<sp/>boxes<sp/>is<sp/>zero,<sp/>return<sp/>zero<sp/>as<sp/>the<sp/>`neg_class_loss`.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">f1():</highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>tf.zeros([batch_size])</highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Otherwise<sp/>compute<sp/>the<sp/>negative<sp/>loss.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">f2():</highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Now<sp/>we&apos;ll<sp/>identify<sp/>the<sp/>top-k<sp/>(where<sp/>k<sp/>==<sp/>`n_negative_keep`)<sp/>boxes<sp/>with<sp/>the<sp/>highest<sp/>confidence<sp/>loss<sp/>that</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>belong<sp/>to<sp/>the<sp/>background<sp/>class<sp/>in<sp/>the<sp/>ground<sp/>truth<sp/>data.<sp/>Note<sp/>that<sp/>this<sp/>doesn&apos;t<sp/>necessarily<sp/>mean<sp/>that<sp/>the<sp/>model</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>predicted<sp/>the<sp/>wrong<sp/>class<sp/>for<sp/>those<sp/>boxes,<sp/>it<sp/>just<sp/>means<sp/>that<sp/>the<sp/>loss<sp/>for<sp/>those<sp/>boxes<sp/>is<sp/>the<sp/>highest.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="178"><highlight class="normal"></highlight></codeline>
<codeline lineno="179"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>To<sp/>do<sp/>this,<sp/>we<sp/>reshape<sp/>`neg_class_loss_all`<sp/>to<sp/>1D...</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>neg_class_loss_all_1D<sp/>=<sp/>tf.reshape(neg_class_loss_all,<sp/>[-1])<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size<sp/>*<sp/>n_boxes,)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>...and<sp/>then<sp/>we<sp/>get<sp/>the<sp/>indices<sp/>for<sp/>the<sp/>`n_negative_keep`<sp/>boxes<sp/>with<sp/>the<sp/>highest<sp/>loss<sp/>out<sp/>of<sp/>those...</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="182"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>values,<sp/>indices<sp/>=<sp/>tf.nn.top_k(neg_class_loss_all_1D,</highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>k=n_negative_keep,</highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sorted=</highlight><highlight class="keyword">False</highlight><highlight class="normal">)<sp/></highlight><highlight class="comment">#<sp/>We<sp/>don&apos;t<sp/>need<sp/>them<sp/>sorted.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="185"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>...and<sp/>with<sp/>these<sp/>indices<sp/>we&apos;ll<sp/>create<sp/>a<sp/>mask...</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="186"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>negatives_keep<sp/>=<sp/>tf.scatter_nd(indices=tf.expand_dims(indices,<sp/>axis=1),</highlight></codeline>
<codeline lineno="187"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>updates=tf.ones_like(indices,<sp/>dtype=tf.int32),</highlight></codeline>
<codeline lineno="188"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>shape=tf.shape(neg_class_loss_all_1D))<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size<sp/>*<sp/>n_boxes,)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>negatives_keep<sp/>=<sp/>tf.to_float(tf.reshape(negatives_keep,<sp/>[batch_size,<sp/>n_boxes]))<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,<sp/>n_boxes)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>...and<sp/>use<sp/>it<sp/>to<sp/>keep<sp/>only<sp/>those<sp/>boxes<sp/>and<sp/>mask<sp/>all<sp/>other<sp/>classification<sp/>losses</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="191"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>neg_class_loss<sp/>=<sp/>tf.reduce_sum(classification_loss<sp/>*<sp/>negatives_keep,<sp/>axis=-1)<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="192"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>neg_class_loss</highlight></codeline>
<codeline lineno="193"><highlight class="normal"></highlight></codeline>
<codeline lineno="194"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>neg_class_loss<sp/>=<sp/>tf.cond(tf.equal(n_neg_losses,<sp/>tf.constant(0)),<sp/>f1,<sp/>f2)</highlight></codeline>
<codeline lineno="195"><highlight class="normal"></highlight></codeline>
<codeline lineno="196"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>class_loss<sp/>=<sp/>pos_class_loss<sp/>+<sp/>neg_class_loss<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="197"><highlight class="normal"></highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>3:<sp/>Compute<sp/>the<sp/>localization<sp/>loss<sp/>for<sp/>the<sp/>positive<sp/>targets.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="199"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/><sp/><sp/><sp/>We<sp/>don&apos;t<sp/>compute<sp/>a<sp/>localization<sp/>loss<sp/>for<sp/>negative<sp/>predicted<sp/>boxes<sp/>(obviously:<sp/>there<sp/>are<sp/>no<sp/>ground<sp/>truth<sp/>boxes<sp/>they<sp/>would<sp/>correspond<sp/>to).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="200"><highlight class="normal"></highlight></codeline>
<codeline lineno="201"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>loc_loss<sp/>=<sp/>tf.reduce_sum(localization_loss<sp/>*<sp/>positives,<sp/>axis=-1)<sp/></highlight><highlight class="comment">#<sp/>Tensor<sp/>of<sp/>shape<sp/>(batch_size,)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="202"><highlight class="normal"></highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>4:<sp/>Compute<sp/>the<sp/>total<sp/>loss.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="204"><highlight class="normal"></highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>total_loss<sp/>=<sp/>(class_loss<sp/>+<sp/>self.<ref refid="classkeras__utils_1_1keras__ssd__loss_1_1_s_s_d_loss_1afb5702fa295ff501d5b4baf09e2af409" kindref="member">alpha</ref><sp/>*<sp/>loc_loss)<sp/>/<sp/>tf.maximum(1.0,<sp/>n_positive)<sp/></highlight><highlight class="comment">#<sp/>In<sp/>case<sp/>`n_positive<sp/>==<sp/>0`</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="206"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Keras<sp/>has<sp/>the<sp/>annoying<sp/>habit<sp/>of<sp/>dividing<sp/>the<sp/>loss<sp/>by<sp/>the<sp/>batch<sp/>size,<sp/>which<sp/>sucks<sp/>in<sp/>our<sp/>case</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="207"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>because<sp/>the<sp/>relevant<sp/>criterion<sp/>to<sp/>average<sp/>our<sp/>loss<sp/>over<sp/>is<sp/>the<sp/>number<sp/>of<sp/>positive<sp/>boxes<sp/>in<sp/>the<sp/>batch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="208"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>(by<sp/>which<sp/>we&apos;re<sp/>dividing<sp/>in<sp/>the<sp/>line<sp/>above),<sp/>not<sp/>the<sp/>batch<sp/>size.<sp/>So<sp/>in<sp/>order<sp/>to<sp/>revert<sp/>Keras&apos;<sp/>averaging</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>over<sp/>the<sp/>batch<sp/>size,<sp/>we&apos;ll<sp/>have<sp/>to<sp/>multiply<sp/>by<sp/>it.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>total_loss<sp/>=<sp/>total_loss<sp/>*<sp/>tf.to_float(batch_size)</highlight></codeline>
<codeline lineno="211"><highlight class="normal"></highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>total_loss</highlight></codeline>
    </programlisting>
    <location file="DeepLearningSuite/DeepLearningSuiteLib/python_modules/keras_utils/keras_ssd_loss.py"/>
  </compounddef>
</doxygen>
